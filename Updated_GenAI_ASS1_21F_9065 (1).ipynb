{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Chn1CWTrUobp",
        "outputId": "73b78681-e237-486f-897b-4fb27410419e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "successfully extracted!\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "zip_path = 'dataset.zip'\n",
        "extract_path = 'dataset'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "print(\"successfully extracted!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EVHYt4XYqa2"
      },
      "source": [
        "Dataset Folder Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOl5MaJ-VDQv",
        "outputId": "5a43a996-94a1-46f7-eba7-6cdfd90ad522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poets Folder: ['habib-jalib', 'nazm-tabatabai', 'naseer-turabi', 'meer-anees', '.DS_Store', 'parveen-shakir', 'mohsin-naqvi', 'jaun-eliya', 'jigar-moradabadi', 'waseem-barelvi', 'javed-akhtar', 'akbar-allahabadi', 'firaq-gorakhpuri', 'jaan-nisar-akhtar', 'mirza-ghalib', 'dagh-dehlvi', 'faiz-ahmad-faiz', 'altaf-hussain-hali', 'ahmad-faraz', 'fahmida-riaz', 'naji-shakir', 'allama-iqbal', 'ameer-khusrau', 'bahadur-shah-zafar', 'gulzar', 'noon-meem-rashid', 'sahir-ludhianvi', 'meer-taqi-meer', 'kaifi-azmi', 'wali-mohammad-wali', 'nida-fazli']\n",
            "Subfolders for habib-jalib: ['.DS_Store', 'hi', 'en', 'ur']\n"
          ]
        }
      ],
      "source": [
        "dataset_dir = 'dataset/dataset'\n",
        "print(\"Poets Folder:\", os.listdir(dataset_dir))\n",
        "#first poet's folder\n",
        "sample_poet = os.listdir(dataset_dir)[0]\n",
        "sample_poet_path = os.path.join(dataset_dir, sample_poet)\n",
        "print(f\"Subfolders for {sample_poet}: {os.listdir(sample_poet_path)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyLJQ8CUYvXr"
      },
      "source": [
        "Total poems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9HP1fXvU7L-",
        "outputId": "f0148108-5c36-4a01-b79b-e597dfc358b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Poems Collected: 1314\n",
            "example Poem:\n",
            " \n",
            "us ra.ūnat se vo jiite haiñ ki marnā hī nahīñ \n",
            "taḳht par baiThe haiñ yuuñ jaise utarnā hī nahīñ \n",
            "yuuñ mah-o-anjum kī vaadī meñ uḌe phirte haiñ vo \n",
            "ḳhaak ke zarroñ pe jaise paañv dharnā hī nahīñ \n",
            "un kā da.avā hai ki sūraj bhī unhī kā hai ġhulām \n",
            "shab jo ham par aa.ī hai us ko guzarnā hī nahīñ \n",
            "kyā ilaaj us kā agar ho mudda.ā un kā yahī \n",
            "ehtimām rañg-o-bū gulshan meñ karnā hī nahīñ \n",
            "zulm se haiñ barsar-e-paikār āzādī-pasand \n",
            "un pahāḌoñ meñ jahāñ par koī jharnā hī nahīñ \n",
            "dil bhī un ke haiñ siyah ḳ\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "dataset_dir = 'dataset/dataset'\n",
        "poetry_texts = []\n",
        "for poet in os.listdir(dataset_dir):\n",
        "    poet_path = os.path.join(dataset_dir, poet)\n",
        "    if os.path.isdir(poet_path):\n",
        "        en_path = os.path.join(poet_path, \"en\")\n",
        "        if os.path.exists(en_path):\n",
        "            for file in os.listdir(en_path):\n",
        "                file_path = os.path.join(en_path, file)\n",
        "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                    poetry_texts.append(f.read())\n",
        "print(f\"Total Poems Collected: {len(poetry_texts)}\")\n",
        "print(\"example Poem:\\n\", poetry_texts[0][:500])  # Print first 500 characters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H6j3W3RY4bF"
      },
      "source": [
        "Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj2ob04lVJEv",
        "outputId": "ea81ed10-90de-46b5-b515-f47f61acbbf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Sample:\n",
            " \n",
            "us ra.ūnat se vo jiite haiñ ki marnā hī nahīñ \n",
            "taḳht par baiThe haiñ yuuñ jaise utarnā hī nahīñ \n",
            "yuuñ mah-o-anjum kī vaadī meñ uḌe phirte haiñ vo \n",
            "ḳhaak ke zarroñ pe jaise paañv dharnā hī nahīñ \n",
            "un kā da.avā hai ki sūraj bhī unhī kā hai ġhulām \n",
            "shab jo ham par aa.ī hai us ko guzarnā hī nahīñ \n",
            "kyā ilaaj us kā agar ho mudda.ā un kā yahī \n",
            "ehtimām rañg-o-bū gulshan meñ karnā hī nahīñ \n",
            "zulm se haiñ barsar-e-paikār āzādī-pasand \n",
            "un pahāḌoñ meñ jahāñ par koī jharnā hī nahīñ \n",
            "dil bhī un ke haiñ siyah ḳ\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "def preprocess_text(text):\n",
        "    return text\n",
        "cleaned_poetry = [preprocess_text(poem) for poem in poetry_texts]\n",
        "print(\"Cleaned Sample:\\n\", cleaned_poetry[0][:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pugIfNqBVYuk",
        "outputId": "2babbc62-5975-4df2-c54a-7c16f3c7e661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchtext==0.15.2\n",
            "  Downloading torchtext-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (1.26.4)\n",
            "Collecting torchdata==0.6.1 (from torchtext==0.15.2)\n",
            "  Downloading torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.1->torchtext==0.15.2) (2.3.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.4)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m303.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.15.2-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m297.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m209.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m222.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m230.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m266.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m216.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m250.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m258.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m240.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m242.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m245.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m268.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m248.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m210.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m267.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata, torchtext\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 torchdata-0.6.1 torchtext-0.15.2 triton-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.0.1 torchtext==0.15.2 --no-cache-dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgW63fQEZId7"
      },
      "source": [
        "Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygoYbrkYVcvj",
        "outputId": "bc1ca1e2-bc31-4986-f264-c9d06dff9106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 17345\n",
            "Encoded Sample Poem: [2, 25, 5471, 4, 18, 778, 10, 15, 856, 29, 14, 2, 1777, 33, 223, 10, 102, 182, 15915, 29]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Tokenize poetry into words\n",
        "def tokenize_poetry(poetry_list):\n",
        "    tokenized_poems = []\n",
        "    for poem in poetry_list:\n",
        "        # Replace actual newlines with a special token\n",
        "        poem = poem.replace(\"\\n\", \" <NEWLINE> \")\n",
        "        tokenized_poems.append(poem.split())  # Tokenize normally\n",
        "    return tokenized_poems\n",
        "\n",
        "\n",
        "# Build vocabulary\n",
        "tokenized_poems = tokenize_poetry(cleaned_poetry)\n",
        "\n",
        "vocab = build_vocab_from_iterator(tokenized_poems, specials=[\"<PAD>\", \"<UNK>\", \"<NEWLINE>\"])\n",
        "vocab.set_default_index(vocab[\"<UNK>\"])\n",
        "\n",
        "\n",
        "# Convert words to indices\n",
        "def encode_poetry(poem):\n",
        "    return [vocab[word] for word in poem]\n",
        "\n",
        "encoded_poems = [encode_poetry(poem) for poem in tokenized_poems]\n",
        "\n",
        "# Print vocabulary size\n",
        "print(f\"Vocabulary Size: {len(vocab)}\")\n",
        "print(\"Encoded Sample Poem:\", encoded_poems[0][:20])  # Show first 10 encoded words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YcbC45q8Vlgf"
      },
      "outputs": [],
      "source": [
        "class SimpleVocab:\n",
        "    def __init__(self, vocab):\n",
        "        self.stoi = vocab.get_stoi()  # Word to index mapping\n",
        "        self.itos = vocab.get_itos()  # Index to word mapping\n",
        "        self.default_index = vocab.get_default_index()  # Default index for unknown words\n",
        "\n",
        "    def __getitem__(self, word):\n",
        "        return self.stoi.get(word, self.default_index)\n",
        "\n",
        "    def lookup_token(self, index):\n",
        "        return self.itos[index] if 0 <= index < len(self.itos) else \"<UNK>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3-V0plwFVp9n"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "simple_vocab = SimpleVocab(vocab)\n",
        "with open('simple_vocab.pkl', 'wb') as f:\n",
        "    pickle.dump(simple_vocab, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCKk_wOzZRTz"
      },
      "source": [
        "Data Preparation for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5Pd6mghVs7q",
        "outputId": "3d27cfd0-e5dc-43ba-95ea-bd744d1cd56a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Input: tensor([   3, 1289,    4,  896,  430,  376])\n",
            "Sample Target: tensor(2)\n"
          ]
        }
      ],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class PoetryDataset(Dataset):\n",
        "    def __init__(self, poems, seq_length=6):\n",
        "        self.seq_length = seq_length\n",
        "        self.data = []\n",
        "\n",
        "        # Create sequences\n",
        "        for poem in poems:\n",
        "            if len(poem) > seq_length:\n",
        "                for i in range(len(poem) - seq_length):\n",
        "                    seq = poem[i:i+seq_length]\n",
        "                    target = poem[i+seq_length]\n",
        "                    self.data.append((seq, target))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sequence, target = self.data[idx]\n",
        "        return torch.tensor(sequence), torch.tensor(target)\n",
        "\n",
        "# Create dataset\n",
        "seq_length = 6\n",
        "dataset = PoetryDataset(encoded_poems, seq_length)\n",
        "\n",
        "# DataLoader\n",
        "batch_size = 32\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Print sample batch\n",
        "for x, y in dataloader:\n",
        "    print(\"Sample Input:\", x[0])\n",
        "    print(\"Sample Target:\", y[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VmOxJMXZW68"
      },
      "source": [
        "LSTM buidling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGpI8DD8VxJA",
        "outputId": "d5edccad-a48c-431a-ca72-34c1b0fa18d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Initialized\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class PoetryLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=256, num_layers=2):\n",
        "        super(PoetryLSTM, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
        "\n",
        "        # Layer Normalization (Added)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        # Apply Layer Normalization\n",
        "        lstm_out = self.layer_norm(lstm_out)\n",
        "\n",
        "        out = self.fc(lstm_out[:, -1])  # Use last LSTM output\n",
        "        return out\n",
        "\n",
        "# Model\n",
        "model = PoetryLSTM(vocab_size=len(vocab)).to(\"cuda\")\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "# Learning Rate Scheduler (Reduce LR after 25 epochs)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n",
        "\n",
        "print(\"Model Initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DWhN6DjZdXC"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAcPRVKnV1jO",
        "outputId": "d22218e9-696e-4cc2-a951-7e6d17c5e709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Loss: 6.3042, Accuracy: 15.07%, LR: 0.000500\n",
            "Epoch [2/30], Loss: 5.5045, Accuracy: 18.36%, LR: 0.000500\n",
            "Epoch [3/30], Loss: 4.8837, Accuracy: 21.01%, LR: 0.000500\n",
            "Epoch [4/30], Loss: 4.2070, Accuracy: 25.13%, LR: 0.000500\n",
            "Epoch [5/30], Loss: 3.4903, Accuracy: 32.92%, LR: 0.000500\n",
            "Epoch [6/30], Loss: 2.8260, Accuracy: 42.26%, LR: 0.000500\n",
            "Epoch [7/30], Loss: 2.2738, Accuracy: 51.13%, LR: 0.000500\n",
            "Epoch [8/30], Loss: 1.8220, Accuracy: 59.13%, LR: 0.000500\n",
            "Epoch [9/30], Loss: 1.4449, Accuracy: 66.52%, LR: 0.000500\n",
            "Epoch [10/30], Loss: 1.1434, Accuracy: 72.83%, LR: 0.000500\n",
            "Epoch [11/30], Loss: 0.8936, Accuracy: 78.27%, LR: 0.000500\n",
            "Epoch [12/30], Loss: 0.7068, Accuracy: 82.41%, LR: 0.000500\n",
            "Epoch [13/30], Loss: 0.5681, Accuracy: 85.69%, LR: 0.000500\n",
            "Epoch [14/30], Loss: 0.4886, Accuracy: 87.63%, LR: 0.000500\n",
            "Epoch [15/30], Loss: 0.4269, Accuracy: 89.14%, LR: 0.000500\n",
            "Epoch [16/30], Loss: 0.3876, Accuracy: 89.97%, LR: 0.000500\n",
            "Epoch [17/30], Loss: 0.3582, Accuracy: 90.70%, LR: 0.000500\n",
            "Epoch [18/30], Loss: 0.3387, Accuracy: 91.19%, LR: 0.000500\n",
            "Epoch [19/30], Loss: 0.3190, Accuracy: 91.72%, LR: 0.000500\n",
            "Epoch [20/30], Loss: 0.3084, Accuracy: 91.90%, LR: 0.000500\n",
            "Epoch [21/30], Loss: 0.2900, Accuracy: 92.43%, LR: 0.000500\n",
            "Epoch [22/30], Loss: 0.2824, Accuracy: 92.52%, LR: 0.000500\n",
            "Epoch [23/30], Loss: 0.2712, Accuracy: 92.89%, LR: 0.000500\n",
            "Epoch [24/30], Loss: 0.2664, Accuracy: 93.05%, LR: 0.000500\n",
            "Epoch [25/30], Loss: 0.2593, Accuracy: 93.22%, LR: 0.000050\n",
            "Epoch [26/30], Loss: 0.0984, Accuracy: 97.58%, LR: 0.000050\n",
            "Epoch [27/30], Loss: 0.0238, Accuracy: 99.75%, LR: 0.000050\n",
            "Epoch [28/30], Loss: 0.0183, Accuracy: 99.76%, LR: 0.000050\n",
            "Epoch [29/30], Loss: 0.0166, Accuracy: 99.76%, LR: 0.000050\n",
            "Epoch [30/30], Loss: 0.0149, Accuracy: 99.77%, LR: 0.000050\n",
            "Training Completed!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "num_epochs = 30\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for x_batch, y_batch in dataloader:\n",
        "        x_batch, y_batch = x_batch.to(\"cuda\"), y_batch.to(\"cuda\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x_batch)\n",
        "\n",
        "        loss = criterion(output, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.detach().item()  # Detach to save memory\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(output, 1)  # Get class with highest probability\n",
        "        correct += (predicted == y_batch).sum().item()\n",
        "        total += y_batch.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total  # Accuracy percentage\n",
        "    scheduler.step()  # Reduce learning rate after step_size epochs\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(dataloader):.4f}, Accuracy: {accuracy:.2f}%, LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "print(\"Training Completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5vmVY9hZgzi"
      },
      "source": [
        "Generating Poetry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acr9wFT8V8Sr",
        "outputId": "5e5ee918-a303-4f15-e5eb-3269645e1844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yeh ishq samajh nah aye\n",
            "daur mujh ko aadam kā lagā hai zarā\n",
            "bin aa.e bane yaañ tak ghar nahīñ miltā\n",
            "merī miTTī se bhī raushan ḳhud hī raste anjuman karūñ\n",
            "maiñ jā.ūñ saaf se yuuñ ham qurbān aayā\n",
            "kah\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def generate_poetry(seed_text, model, vocab, max_words=40):\n",
        "    model.eval()\n",
        "    words = seed_text.split()\n",
        "\n",
        "    for _ in range(max_words):\n",
        "        encoded = torch.tensor([vocab[word] for word in words[-6:]]).unsqueeze(0).to(\"cuda\")\n",
        "        with torch.no_grad():\n",
        "            output = model(encoded)\n",
        "            next_word = vocab.lookup_token(output.argmax().item())\n",
        "            words.append(next_word)\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "# Example Usage\n",
        "seed = \"yeh ishq samajh nah aye\"\n",
        "def print_poetry(generated_text):\n",
        "    formatted_text = generated_text.replace(\" <NEWLINE> \", \"\\n\")\n",
        "    return formatted_text\n",
        "\n",
        "generate=generate_poetry(seed, model, vocab)\n",
        "print(print_poetry(generate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKszcEpxWALn"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"poetry_lstm_model.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}